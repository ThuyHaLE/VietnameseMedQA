{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhDbLuMjCRHibSNYD7lLKt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0YCpITWOSKfQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699629280575,"user_tz":-420,"elapsed":23147,"user":{"displayName":"Hạ Lê (翠夏)","userId":"01819704699029854720"}},"outputId":"24eb5eee-921b-4407-e050-6fa2e69c354d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers==4.34.0 datasets==2.14.5 accelerate==0.23.0 evaluate==0.4.1 peft==0.5.0"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","from peft import get_peft_model, LoraConfig, TaskType\n","\n","model_name = 'google/flan-t5-base'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","# peft_config = LoraConfig(r=8, lora_alpha=32, lora_dropout=0.05, target_modules=[\"query\", \"vavlue\"], bias=\"none\")\n","# model = get_peft_model(model, peft_config)"],"metadata":{"id":"ro1d0SnjXjKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#modified_MCQA (MedMCQA&FrenchMedMCQA)\n","!gdown 1e5FHk1tmAy_VmyfgTi42lnzvHUM2Zmo0\n","!unzip modified_MCQA.zip"],"metadata":{"id":"rZSTrVX4yw96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from datasets import DatasetDict\n","\n","data_dir = '.'\n","raw_dataset = {\n","    'train': load_dataset('json', data_files=f'{data_dir}/MCQA_train.json')['train'],\n","    'valid': load_dataset('json', data_files=f'{data_dir}/MCQA_dev.json')['train']\n","}\n","raw_dataset = DatasetDict(raw_dataset)"],"metadata":{"id":"F-uMwa6VXunC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataloader\n","import torch\n","def id_labeling(num_opts):\n","  option_dict = {2: ['a', 'b'],\n","                 3: ['a', 'b', 'c','ab', 'ac', 'bc','abc'],\n","                 4: ['a', 'b', 'c', 'd', 'ab', 'ac', 'ad', 'bc', 'bd', 'cd','abc', 'abd', 'acd', 'bcd','abcd'],\n","                 5: ['a', 'b', 'c', 'd', 'e', 'ab', 'ac', 'ad', 'ae', 'bc', 'bd', 'be', 'cd', 'ce', 'de', 'abc', 'abd', 'abe', 'acd',\n","                     'ace', 'ade', 'bcd', 'bce', 'bde', 'cde', 'abcd', 'abce', 'abde', 'acde', 'bcde','abcde']}\n","  if num_opts in [2,3,4,5]:\n","    label_list = option_dict[num_opts]\n","    id2label = {}\n","    label2id = {}\n","    for idx, label in enumerate(label_list):\n","      id2label[idx] = label\n","      label2id[label] = idx\n","    num_labels = len(id2label)\n","    return id2label, label2id, num_labels\n","\n","def preprocess_function(examples, max_seq_length, tokenizer):\n","    # Tokenize the texts\n","    sentences = []\n","    labels = []\n","    for example in zip(examples[\"question\"], examples[\"context\"],\n","                       examples['answer_a'], examples['answer_b'], examples['answer_c'],\n","                       examples['answer_d'], examples['answer_e'], examples['label']):\n","        question = example[0]\n","        context = example[1]\n","        answer_a = example[2]\n","        answer_b = example[3]\n","        answer_c = example[4]\n","        answer_d = example[5]\n","        answer_e = example[6]\n","        opt_lst = [answer_a, answer_b, answer_c, answer_d, answer_e]\n","        choices = ''\n","        for opt in opt_lst:\n","          if str(opt) != 'nan':\n","            choices += \". \\n \" + opt\n","        prompt = f\"Question: {question}. Choice the correct answers from: {choices}. Context: {context}.\"\n","        sentences.append(prompt)\n","\n","        answer = id2label[int(example[7])]\n","        labels.append(answer)\n","\n","    model_inputs = tokenizer(sentences,\n","                             padding=\"max_length\",\n","                             max_length=max_seq_length,\n","                             truncation=True)\n","    labels = tokenizer(labels, padding=True)\n","\n","    model_inputs[\"labels\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]]\n","    return model_inputs"],"metadata":{"id":"SG-iUQjAX48o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from functools import partial\n","id2label, label2id, num_labels = id_labeling(5)\n","processed_dataset = raw_dataset.map(partial(preprocess_function,\n","                                            max_seq_length=256,\n","                                            tokenizer=tokenizer),\n","                                    batched=True,\n","                                    load_from_cache_file=False,\n","                                    remove_columns=['id', 'question', 'answer_a', 'answer_b', 'answer_c',\n","                                                    'answer_d', 'answer_e', 'label', 'context', 'bert_text'],\n","                                    desc=\"Running tokenizer on dataset\",)"],"metadata":{"id":"bAZSjz8EX9ho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Metric\n","import numpy as np\n","import evaluate\n","from transformers import EvalPrediction\n","\n","def postprocess_text(predictions, labels):\n","    predictions = [prediction.strip() for prediction in predictions]\n","    labels = [label2id[label.strip()] for label in labels]\n","\n","    for idx in range(len(predictions)):\n","        if predictions[idx] in label2id:\n","           predictions[idx] = label2id[predictions[idx]]\n","        else:\n","            predictions[idx] = '-100'\n","    return predictions, labels\n","\n","def load_metric(metric_name):\n","    if metric_name == \"accuracy\":\n","        return evaluate.load(\"accuracy\")\n","    elif metric_name == \"f1\":\n","        return evaluate.load(\"f1\")\n","\n","def seq2seq_compute_metrics(tokenizer, metric):\n","    def compute_metrics(eval_pred: EvalPrediction):\n","        nonlocal tokenizer, metric\n","        predictions, labels = eval_pred\n","        if isinstance(predictions, tuple):\n","            predictions = predictions[0]\n","\n","        predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","        # Replace -100 in the labels as we can't decode them.\n","        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","        predictions, labels = postprocess_text(predictions, labels)\n","        result = metric.compute(predictions=predictions, references=labels)\n","        return result\n","    return compute_metrics"],"metadata":{"id":"80v1xhFMX_WZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Trainer\n","import transformers\n","from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","label_pad_token_id = -100\n","task = \"MedMCQA&FrenchMCQA\"\n","metric = load_metric(\"accuracy\")\n","compute_metrics = seq2seq_compute_metrics(tokenizer, metric)\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer,\n","                                       model=model,\n","                                       label_pad_token_id=label_pad_token_id,\n","                                       pad_to_multiple_of=8)\n","\n","EPOCHS = 3\n","training_args = Seq2SeqTrainingArguments(f\"{model_name}-finetuned-{task}-v{1}\",\n","                                         num_train_epochs=EPOCHS,\n","                                         per_device_train_batch_size=16,\n","                                         per_device_eval_batch_size=64,\n","                                         evaluation_strategy='steps',\n","                                         save_strategy='steps',\n","                                         save_steps=2000,\n","                                         eval_steps=2000,\n","                                         save_total_limit=EPOCHS,\n","                                         predict_with_generate=True,\n","                                         load_best_model_at_end=True,\n","                                         metric_for_best_model='accuracy')\n","\n","trainer = Seq2SeqTrainer(model=model,\n","                         args=training_args,\n","                         data_collator=data_collator,\n","                         compute_metrics=compute_metrics,\n","                         train_dataset=processed_dataset['train'],\n","                         eval_dataset=processed_dataset['valid'])"],"metadata":{"id":"Mupy4hhsYEmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"huzZKS7mYGTp"},"execution_count":null,"outputs":[]}]}